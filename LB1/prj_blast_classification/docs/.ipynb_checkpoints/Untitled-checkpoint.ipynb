{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive classificator method based on blast search needs an e-value threshold to minimize the erroneus assignments between kunitz and non-kunitz proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "Create a file with these columns from the blast output\n",
    "\n",
    "1 identifier\n",
    "\n",
    "2 e-value\n",
    "\n",
    "3 class (0 = negative, non-kunitz; 1 = positive, kunitz)\n",
    "\n",
    "NOTE: in the blast output:\n",
    "\n",
    "1 query id\n",
    "\n",
    "2 target id\n",
    "\n",
    "\\[...\\]\n",
    "\n",
    "11 e-value\n",
    "\n",
    "## List the minimum e-value for each sequence\n",
    "First, we need to select the minimum e-value obtained from the blast search for each sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alessandro/Unibo/python-programming-alessandro-lussana/LB1/prj/dataset\n",
      "sp|A0A0D3MJQ5|ARSM_CLOSP\t4.3\n",
      "sp|A0JNI5|CLASR_BOVIN\t33\n",
      "sp|A0K1I7|TRMB_ARTS2\t53\n",
      "sp|A0L5J3|RNY_MAGMM\t30\n",
      "sp|A0M8V0|CAZA2_CANLF\t236\n",
      "sp|A1A8R7|SYL_ECOK1\t8.7\n",
      "sp|A1ASM0|APT_PELPD\t123\n",
      "sp|A1B9H5|RL21_PARDP\t194\n",
      "sp|A1BF89|PUR7_CHLPD\t33\n",
      "sp|A1BI83|3MGH_CHLPD\t145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tlist_min_evalues\n",
      "\t1\n",
      "\n",
      "rule list_min_evalues:\n",
      "    input: sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_run.gz\n",
      "    output: sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_min_eval.gz\n",
      "    jobid: 0\n",
      "    wildcards: blast_run=sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot\n",
      "\n",
      "for id in $(zcat sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_run.gz | cut -f2 | sort | uniq); do zcat sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_run.gz | grep $id | cut -f2,11 | LC_ALL=c sort -gk2 | sed -n '1p'; done | gzip > sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_min_eval.gz\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n",
      "Provided cores: 1\n",
      "Rules claiming more threads will be scaled down.\n",
      "Job counts:\n",
      "\tcount\tjobs\n",
      "\t1\tlist_min_evalues\n",
      "\t1\n",
      "\n",
      "rule list_min_evalues:\n",
      "    input: sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_run.gz\n",
      "    output: sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_min_eval.gz\n",
      "    jobid: 0\n",
      "    wildcards: blast_run=sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot\n",
      "\n",
      "for id in $(zcat sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_run.gz | cut -f2 | sort | uniq); do zcat sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_run.gz | grep $id | cut -f2,11 | LC_ALL=c sort -gk2 | sed -n '1p'; done | gzip > sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_min_eval.gz\n",
      "Finished job 0.\n",
      "1 of 1 steps (100%) done\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../dataset/\n",
    "pwd\n",
    "snakemake -p sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_min_eval.gz\n",
    "snakemake -p sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_pf00014_non_human_id_filter_on_swissprot_blast_min_eval.gz\n",
    "zcat sprot_pf00014_human_id_filter_on_swissprot_vs_sprot_non_pf00014_global_id_sampled500_filter_on_swissprot_blast_min_eval | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check consistency in number of lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blastclust \n",
    "blastclust -i ids_kunitz.fasta -o ids_kunits.clust -L 0.8 -S 90\n",
    "\n",
    "clusters together the sequences that share 90% sequence identity for 0.8 sequence length(?). The output is sorted such that in the first line there is the cluster with the greatest number of sequences\n",
    "\n",
    "This will be very useful for checking and removing redundancy when considering queries in PDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM classificator framework\n",
    "* fectch pdb for kunitz and non-kunitz\n",
    "* check for redundancy and filter\n",
    "* train hmm with training set\n",
    "* optimize threshold\n",
    "* test hmm with different set (do some ten-fold cross-validation)\n",
    "* do further tests that will be discussed later\n",
    "\n",
    "### fectch pdb files\n",
    "Use RCSB PDB advanced search; note that you can filter for mutations, co-crystallization..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
