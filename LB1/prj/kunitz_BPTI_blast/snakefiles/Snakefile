#######################################################################
### BPTI_Kunitz/non-BPTI_Kunitz psiblast-based binary classificator ###
#######################################################################

###############################################################################
##### Run complete analysis ###################################################
#                                                                             #
# ### Roc Curve ###                                                           #
#                                                                             #
# roc/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.\                #
# sprot_pf00014_non_human_id_filter_on_swissprot.and.\                        #
# sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.\                    #
# sprot_non_pf00014_global_id_samp559276_filter_on_swissprot.txt              #
#                                                                             #
# ### Confusion Matrix ###                                                    #
#                                                                             #
# confmat/th.{th}.of.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.\ #
# sprot_pf00014_non_human_id_filter_on_swissprot.and.\                        #
# sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.\                    #
# sprot_non_pf00014_global_id_samp559276_filter_on_swissprot                  #
#                                                                             #
###############################################################################

# create needed symbolic links in dataset/ pointing to handmade/ files
# try:
# snakemake -p create_links
rule create_links:
    shell:
        "ln -s ../handmade/sprot_non_pf00014_global_id.txt"
        " sprot_non_pf00014_global_id.txt;"
        " ln -s ../handmade/sprot_pf00014_global_id.txt"
        " sprot_pf00014_global_id.txt;"
        " ln -s ../handmade/sprot_pf00014_human_id.txt"
        " sprot_pf00014_human_id.txt;"
        " ln -s ../handmade/sprot_pf00014_non_human_id.txt"
        " prot_pf00014_non_human_id.txt;"
        " ln -s ../../kunitz_BPTI_hmm/dataset/swissProt.fasta.gz"
        " swissprot.fasta.gz"

# index a protein database in fasta format
# try:
# alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/db$ \
# snakemake -p uniprot_sprot.phr
# MEMO: the rule will also generate the following two files
# {db}.pin
# {db}.psq
rule index_protein_database:
    input:
        "{db}.fasta.gz"
    output:
        phr="{db}.fasta.phr"
    params:
        "{db}"
    shell:
        "zcat {input} > {params}.fasta;"
        " makeblastdb -in {params}.fasta -out {params}.fasta -dbtype prot"

# run blast on local database; the output is in tabular format and
# list the target identifiers with their lowest e-value
# try:
# positives: db_searches/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.search_out
# negatives: db_searches/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.search_out
# MEMO: e-value is stored in 11th column in the raw output
# MEMO -evalue option is hard-coded: basically you want to get printed every score
rule blast_run:
    input:
        db="{database}.fasta.gz",
        query="{query}.fasta",
        phr="{database}.fasta.phr"
    output:
        "db_searches/{query}.psiblast.vs.{database}.search_out"
    params:
        db="{database}",
        q="{query}"
    shell:
        "zcat {input.db} > {params.db}.fasta;"
        " psiblast -query {input.query} -db {params.db}.fasta -evalue 1000000000 -outfmt 6 -out db_searches/{params.q}.psiblast.vs.{params.db}.search_raw;"
        " for id in $(cat db_searches/{params.q}.psiblast.vs.{params.db}.search_raw | cut -f2 | sort | uniq); do"
        " cat db_searches/{params.q}.psiblast.vs.{params.db}.search_raw | grep $id | cut -f2,11 | LC_ALL=c sort -gk2 | sed -n '1p' | gawk '{{print $1\" - - - - - - \"$2}}';"
        " done > {output};"

# fetch the sequences from uniprot given a list of uniprot IDs
# try:
# alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/db$ \
# snakemake -p id_for_MSA.fasta.gz
rule fetch_fasta_from_uniprot:
    input:
        "{id_list}.txt"
    output:
        "{id_list}.uniprot.fasta.gz"
    shell:
        "mkdir tmp;"
        " for i in $(cat {input}); do"
        " wget https://www.uniprot.org/uniprot/$i.fasta -O tmp/$i.fasta; done;"
        " cat tmp/*.fasta | gzip > {output};"
        " rm -fr tmp/"

# filter a multifasta given a list of identifiers
# try:
# snakemake -p idlist_filter_on_uniprot_sprot.fasta.gz
rule filterfasta:
    input:
        db = "{db}.fasta.gz",
        fl = "{filter}.txt"
    output:
        "{filter}_filter_on_{db}.fasta.gz"
    shell:
        "python ../src/fastafilter.py {input.db} {input.fl} | gzip > {output}"

# sample N items from a list
# try:
# snakemake -p sprot_non_pf00014_global_id_samp500.txt
rule random_sampling:
    input:
        "{list}.txt"
    output:
        "{list}_samp{N}.txt"
    params:
        "{N}"
    shell:
        "cat {input} | sort -R | sed -n '1,{params}p' > {output}"

########################
# Performance analysis #
########################

# generate list of examples to then feed a confusion matrix
# try:
# snakemake -p analysis/conflst.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.gz
rule compute_confusion_matrix_feed_file:
    input:
        p="db_searches/{p}.search_out",
        n="db_searches/{n}.search_out"
    output:
        "analysis/conflst.{p}.and.{n}.gz"
    shell:
        "cat"
        " <(cat {input.p} | grep ^sp | tr -s \" \" \"\\t\" | cut -f1,8"
        " | awk '{{print $0\"\\t1\"}}')"
        " <(cat {input.n} | grep ^sp | tr -s \" \" \"\\t\" | cut -f1,8"
        " | awk '{{print $0\"\\t0\"}}')"
        " | gzip > {output}"

# add the non-hits sequences to the conflist file assigning e-value=1
# try:
# snakemake -p analysis/filledconflst.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.gz
rule add_missing_id_to_conf_list:
    input:
        cl="analysis/conflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz",
        id="sprot_non_pf00014_global_id_samp{size}.txt"
    output:
        "analysis/filledconflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz"
    shell:
        "cat <(zcat {input.cl}) <(cat {input.id} | cut -f1"
        " | grep -v -f <(zcat {input.cl} | cut -d '|' -f2)"
        " | awk '{{print $0\"\\t1.0\\t0\"}}') | gzip > {output}"

# divide e-values by the database size in filled.conflist files
# try:
# snakemake -p analysis/corrconflst.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.gz
rule correct_e_values:
    input:
        "analysis/filledconflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz" 
    output:
        "analysis/corrconflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz" 
    shell:
        "N=$(zcat {input} | awk '$3==0{{print $0}}' | wc -l);"
        " P=$(zcat {input} | awk '$3==1{{print $0}}' | wc -l);"
        " zcat {input} | awk -v P=$P -v N=$N"
        " '{{if($2 != 1.0 && $3 == 1){{print $1\"\\t\"$2/P\"\\t\"$3}}"
        "else if($2 != 1.0 && $3 == 0){{print $1\"\\t\"$2/N\"\\t\"$3}}"
        " else{{print $0}}}}' | gzip > {output}"

# compute points and auc of roc + plot (python based)
# try:
# snakemake -p roc/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.txt
rule compute_roc_py:
    input:
        "analysis/corrconflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz"
    output:
        "roc/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.txt"
    params:
        n="{size}",
        fig="roc/psiblast_sampN{size}.png"
    shell:
        "python ../src/roc.py {input} {params.n} {params.fig} > {output}"

# show confusion matrix at a given threshold
# try:
# snakemake -p roc/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot.th0.000001
#rule show_confusion_matrix:
#    input:
#        "analysis/corrconflst."
 #       "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
#        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
#        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
#        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot.gz"
#    output:
#        "roc/sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
#        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
#        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
#        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot."
#        "th{th}"
#    params:
#        "{th}"
#    shell:
#        "python ../src/confMatPrettyPrint.py {input} {params}"

# compute confusion matrix at a given threshold and print analysis results +
# show confusion matrix in a plot
# try:
# snakemake -p confmat/th0.00001.of.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_pf00014_non_human_id_filter_on_swissprot.and.sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs.sprot_non_pf00014_global_id_samp500_filter_on_swissprot
rule compute_confusion_matrix:
    input:
        "analysis/corrconflst."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot"
        ".gz"
    output:
        "confmat/th{th}.of."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_pf00014_non_human_id_filter_on_swissprot.and."
        "sprot_pf00014_human_id_filter_on_swissprot.psiblast.vs."
        "sprot_non_pf00014_global_id_samp{size}_filter_on_swissprot"
    params:
        th="{th}",
        imgname="confmat/psiblast_th{th}_samp{size}.png"
    shell:
        "python ../src/buildConfMatrix.py {input} {params.th} > {output};"
        "python ../src/confMatPrettyPrint.py {input} {params.th} {params.imgname}"

# ----------------------------------------------------------------------------#

#############################
# HMM rules - not used here #
#############################

# train a hidden markov model with hmmer from an alignment in stockholm format
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p globin.hmm
rule build_hmm:
    input:
        "{msa}.sto"
    output:
        "{msa}.hmm"
    shell:
        "hmmbuild {output} {input}"

# generate random sequences with a hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p globin_emit5.fasta.gz
rule emit_sequence:
    input:
        "{model}.hmm"
    output:
        "{model}_emit{N}.fasta.gz"
    params:
        "{N}"
    shell:
        "hmmemit -N {params} {input} | gzip > {output}"

# perform database search with a hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p globin_vs_globin_emit5.search_out.gz
rule hmm_db_search:
    input:
        "{db}.fasta.gz"
    output:
        "{model}_vs_{db}.search_out.gz"
    params:
        "{model}.hmm"
    shell:
        "hmmsearch {params} <(zcat {input}) | gzip > {output}"

# create a library of models to efficiently perform database search
# W! hmm files have to be concat together manually
# TODO solve the W
# this rule also creates the following files:
# {models}.hmm.h3m
# {models}.hmm.h3f
# {models}.hmm.h3p
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p global.hmm.h3i
rule build_hmm_library:
    input:
        "{models}.hmm"
    output:
        "{models}.hmm.h3i"
    params:
        "{models}"
    shell:
        "hmmpress {params}.hmm"

# scan a database with a library of hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p global_vs_globin_emit5.scan_out.gz
rule hmm_db_scan:
    input:
        "{db}.fasta.gz"
    output:
        "{models}_vs_{db}.scan_out.gz"
    params:
        "{models}.hmm"
    shell:
        "hmmscan {params} <(zcat {input}) | gzip > {output}"

#######################################
# Run MSA with Muscle - not used here #
#######################################

# perform MSA with muscle using default parameters
# try:
# alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/db$ \
# snakemake -p id_for_MSA_muscle_out.aln.gz
# TODO add params to tune the muscle's parameters
rule muscle_align:
    input:
        "{sequences}.fasta.gz"
    output:
        "{sequences}_muscle_out.aln.gz"
    shell:
        "muscle -in <(zcat {input}) | gzip > {output}"

####################
# deprecated rules #
####################

# filter a multifasta given a list of identifiers
# try:
# snakemake -p idlist_filter_on_uniprot_sprot.fasta.gz
# W! Snakemake thinks that the output file might be corrupted;
# the rule works actually properly
#rule filterfasta:
#    input:
#        "{db}.fasta.gz"
#    output:
#        "{filter}_filter_on_{db}.fasta.gz"
#    params:
#        "{filter}.txt"
#    shell:
#        "for entry in $(cat {params}); do"
#        " zcat uniprot_sprot.fasta.gz | awk -v entry=$entry"
#        " '{{ if($0~entry){{print $0; getline; while($0 !~ /^>/)"
#        " {{print $0; getline}}; exit }} }}'; done"
#        " | gzip > {output}"
#
# run blast on local database; the output is in tabular format
# try:
# alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/db$ \
# snakemake -p query_vs_uniprot_sprot_e0.001_blast_out.gz
#rule homology_search:
#    input:
#        db="{database}.fasta",
#        query="{query}.fasta",
#        phr="{database}.fasta.phr"
#    output:
#        "{query}_vs_{database}_e{evalue}_blast_out.gz"
#    params:
#        "{evalue}"
#    shell:
#        "blastpgp -i {input.query} -d {input.db} -e {params} -m 8"
#        "| gzip > {output}"
