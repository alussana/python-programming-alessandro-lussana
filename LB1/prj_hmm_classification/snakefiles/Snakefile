# create a tsv with rcsbpdb ids consistent with parse_pdbefold_summary output
# .META:
# 1 ID_CHAIN
# 2 Resolution
# 3 Taxonomy
# 4 Sequence
# 5 Chain Length
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p rcsbpdb_wt_PF00014_len50_90.txt.gz 
rule parse_rcsbpdb_table:
    input:
        "rcsbpdb_wt_PF00014_len50_90.csv"
    output:
        "rcsbpdb_wt_PF00014_len50_90.txt.gz"
    shell:
        "cat {input} | sed 's/,/\t/g' | sed 's/\"//g' | sed 's/ /_/g'"
        " | sed '1d' | sed 's/\t/_/' | gzip > {output}"

# create a tsv with pdbefold ids consistent with parse_rcsbpdb_table output
# .META:
# 1 ID_CHAIN
# 2 Q-score
# 3 P-score
# 4 Z-score
# 5 RMSD
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p pdbefold_5pti_A_summary.txt.gz
rule parse_pdbefold_summary:
    input:
        "pdbefold_5pti_A_summary"
    output:
        "pdbefold_5pti_A_summary.txt.gz"
    shell:
        "cat {input} | sed '1,5d' | tr -s \" \" \"\\t\" | cut -f3-"
        " | awk '{{print toupper($17)\"\t\"$1\"\t\"$2\"\t\"$3\"\t\"$4}}'"
        " | sed 's/:/_/' | gzip > {output}"

# merge the fields of two tsv files joining them on the first column
# .META:
# 1 ID_CHAIN
# 2 Resolution
# 3 Taxonomy
# 4 Sequence
# 5 Chain Length
# 6 Q-score
# 7 P-score
# 8 Z-score
# 9 RMSD
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary.txt.gz
rule intersect_with_all_data:
    input:
        t1="{t1}.txt.gz",
        t2="{t2}.txt.gz"
    output:
        "intersec_{t1}_and_{t2}.txt.gz"
    shell:
        "join -j 1"
        " <(zcat {input.t1} | sort) <(zcat {input.t2} | fgrep -f"
        " <(zcat {input.t1} | cut -f1) | sort )"
        " | sed 's/ /\t/g' | gzip > {output}"

# create a fasta from the intersection table
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary.fasta
rule intersection2fasta:
    input:
        "intersec_{t1}_and_{t2}.txt.gz"
    output:
        "intersec_{t1}_and_{t2}.fasta"
    shell:
        "zcat {input} | awk '{{print \">\"$1\"\\n\"$4}}' > {output}"

# run blastclust with custom -L and -S parameters
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary_S99_L0.95_blastclust_out.gz
rule run_blastclust:
    input:
        "{db}.fasta"
    output:
        "{db}_S{S}_L{L}_blastclust_out.gz"
    params:
        S="{S}",
        L="{L}"
    shell:
        "blastclust -i {input} -L {params.L} -S {params.S} | gzip > {output}"

# filter for redundancy the intersection table given sequences clusters
# for every cluster one sequence in selected as representative of that cluster
# the criterium for selection is lowest resolution of the structure
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p chosen_blastclust_seq_for_intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary_S99_L0.95.txt 
rule extract_representative_sequences:
    input:
        clust="{sequences}_S{S}_L{L}_blastclust_out.gz",
        table="{sequences}.txt.gz"
    output:
        "chosen_blastclust_seq_for_{sequences}_S{S}_L{L}.txt"
    shell:
        "for cluster in $(zcat {input.clust} | sed '1d' | sed 's/ /%/g'); do"
        " zcat {input.table} | grep -w -f <(echo $cluster | sed 's/%/\\n/g') | sort -n -k2"
        " | sed -n '1p'; done > {output}"

# create a fasta from the intersection table
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p chosen_blastclust_seq_for_intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary_S99_L0.95.fasta.gz
rule filtered_intersection2fasta:
    input:
        "chosen_blastclust_seq_for_{sequences}_S{S}_L{L}.txt"
    output:
        "chosen_blastclust_seq_for_{sequences}_S{S}_L{L}.fasta.gz"
    shell:
        "cat {input} | awk '{{print \">\"$1\"\\n\"$4}}' | gzip > {output}"

# perform MSA with muscle using default parameters
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p chosen_blastclust_seq_for_intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary_S99_L0.95.muscle.afa
# TODO add params to tune the muscle's parameters
rule muscle_align:
    input:
        "{sequences}.fasta.gz"
    output:
        "{sequences}.muscle.afa"
    shell:
        "muscle -in <(zcat {input}) > {output}"

# train a hidden markov model with hmmer from an alignment in aligned fasta format
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1/prj_hmm_classification/dataset$ \
# snakemake -p chosen_blastclust_seq_for_intersec_rcsbpdb_wt_PF00014_len50_90_and_pdbefold_5pti_A_summary_S99_L0.95.muscle.hmm
rule build_hmm:
    input:
        "{msa}.{source}.afa"
    output:
        "{msa}.{source}.hmm"
    shell:
        "hmmbuild --informat afa {output} {input}"

# generate random sequences with a hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p globin_emit5.fasta.gz
rule emit_sequence:
    input:
        "{model}.hmm"
    output:
        "{model}_emit{N}.fasta.gz"
    params:
        "{N}"
    shell:
        "hmmemit -N {params} {input} | gzip > {output}"

# perform database search with a hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p globin_vs_globin_emit5.search_out.gz
rule hmm_db_search:
    input:
        "{db}.fasta.gz"
    output:
        "{model}_vs_{db}.search_out.gz"
    params:
        "{model}.hmm"
    shell:
        "hmmsearch {params} <(zcat {input}) | gzip > {output}"

# create a library of models to efficiently perform database search
# W! hmm files have to be concat together manually
# TODO solve the W
# this rule also creates the following files:
# {models}.hmm.h3m
# {models}.hmm.h3f
# {models}.hmm.h3p
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p global.hmm.h3i
rule build_hmm_library:
    input:
        "{models}.hmm"
    output:
        "{models}.hmm.h3i"
    params:
        "{models}"
    shell:
        "hmmpress {params}.hmm"

# scan a database with a library of hmm
# try:
# (base) alessandro@MULE:~/Unibo/python-programming-alessandro-lussana/LB1$ \
# snakemake -p global_vs_globin_emit5.scan_out.gz
rule hmm_db_scan:
    input:
        "{db}.fasta.gz"
    output:
        "{models}_vs_{db}.scan_out.gz"
    params:
        "{models}.hmm"
    shell:
        "hmmscan {params} <(zcat {input}) | gzip > {output}"

# filter a multifasta given a list of identifiers
# try:
# snakemake -p idlist_filter_on_uniprot_sprot.fasta.gz
rule filterfasta:
    input:
        db = "{db}.fasta.gz",
        fl = "{filter}.txt"
    output:
        "{filter}_filter_on_{db}.fasta.gz"
    shell:
        "python ../src/fastafilter.py {input.db} {input.fl} | gzip > {output}"

# sample N items from a list
# try:
# snakemake -p sprot_pf00014_non_human_id_sampled18.txt
rule random_sampling:
    input:
        "{list}.txt"
    output:
        "{list}_sampled{N}.txt"
    params:
        "{N}"
    shell:
        "cat {input} | sort -R | sed -n '1,{params}p' > {output}"
